# SwiftUIClosedCaptioning

The latest version of SFSpeechRecognizer allows offline speech-to-text, amongst other new features. This project builds on the work of other devs to create a demo of how closed captioning could work with video playback.

The benefits of offline transcription is no more data usage, no more need for a data connection at all, and unlimited usage (Apple restricted transcription to 1-minute at a time and for limited hits per day). The downside is that it may not be as accurate nor have the benefit of a constantly learning cloud.

The potential applications, however, are huge for Accessibility purposes. Combined with CoreML/CreateML Speech capabilities, it can potentially open up a number of use cases.

## Authors

* **Danny Bolella** - *Initial work* - [TheDB](https://dbolella.github.io/)

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## SUPER Acknowledgments

Essentially forked from https://github.com/peacemoon/SFSpeechRecognizerRealtimeVideoCaptioning, which was forked from https://github.com/zats/SpeechRecognition, and uses the Swift version of the Audio Processor found in https://github.com/gchilds/MTAudioProcessingTap-in-Swift.

Phew.
